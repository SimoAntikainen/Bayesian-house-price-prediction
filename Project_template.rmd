---
title: "House selling price prediction"
author: "Anonymous"
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(dev="png")
knitr::opts_chunk$set(dpi=200)
```

# 1. Introduction

Online services such as zillow zestimates [1] provide accuarate information on how much houses sell for using gathered data, providing useful information for the realtor and the person selling the house. This notebook explores the possibilities on using stan to build regression models to predict housing prices on an zipcode level.     

[1] https://www.zillow.com/zestimate/


```{r,message=FALSE, warning=FALSE}
library(rstan)
options(mc.cores = 4)#parallel::detectCores())
library(ggplot2)
library(matrixStats)
library(dplyr)
library(GGally)
library(corrplot)
library(reshape2)
library(ElemStatLearn)
library(glmnet)
library(plotmo)
library(Metrics)
library(bayesplot)
library(loo)
set.seed(42)
```

# 2. Dataset description

For the prediction task we have chosen House Sales in King County, USA dataset [2], which provides data for the houses sold between May 2014 / May 2015 in the area in an regression friendly form.   
[2] https://www.kaggle.com/harlfoxem/housesalesprediction

```{r}
houseprice = read.csv("data/kc_house_data.csv", header = TRUE)

#suffle rows to guarantee no row depencies 
houseprice = houseprice[sample(nrow(houseprice)),]

#drop colinear columns sqft_living = sqft_above + sqft_basement
houseprice = subset(houseprice, select = -c(sqft_above, sqft_basement))

#transform the depended variable to log scale to  ensure better numerical accuracy
houseprice$log_price = log(houseprice$price)


datecol <- as.POSIXct(houseprice$date, format="%Y%m%dT%H%M%S")
houseprice$date_num = as.numeric(datecol)
unique_zips = unique(houseprice$zipcode)
houseprice$mutated_zipcode = match(houseprice$zipcode,  unique_zips)
head(houseprice)
```

```{r}
M <- cor(houseprice[-2], method="spearman")
corrplot(M, method = "circle")
```

As the used dataset contains multiple predictors with linear and non-linear depencies, we use lasso regression to perform variable selection on the dataset to find an smaller subset of predictor variables to use in our model. This is neccessary for the purposes of the notebook to speed up the calculations and to better guarantee convergence. 
!Notice that Lasso regression estimates are calculated using an linear model so they might not be the best predictors for an non-linear model. 

```{R}
houseprice_scaled <- mutate_if(houseprice, is.numeric, list(~scale(.) %>% as.vector))

response = houseprice_scaled[3]
obs = houseprice_scaled[4:19]
ridge_regression <- glmnet(y=data.matrix(response), x=data.matrix(obs), alpha = 1)
plot_glmnet(ridge_regression, xvar = "lambda", label = TRUE)
```

From the lasso regression plot we can see that: sqft_living, grade, lat, view, waterfront, yr_built, sqft_living15, bathrooms and long are the 9 best variables for the model.
When they are plotted in the matrix plot underneath, we can see that they chosen variables exhibit various linear and nonlinear effects on price.
We choose all of these variables for the stan model except for the waterfront variable. Waterfront variable is not used as its binary nature causes problems in convergence in the case of polynomial model used.

```{r,fig.height = 9, fig.width = 9}
ggpairs(houseprice  %>% select(price, sqft_living, grade, lat, view, waterfront, yr_built, 
                               sqft_living15, bathrooms, long))
```


# 3. Model description

We fit two varying intercept regression models: an multiple linear and an multiple polynomial model. Varying intercept models are multilevel models, which make use of partial pooling 

## 3.1 Prior choices

In [3] it is recommended to scale the parameters to unit scale and to use student-t distribution $t_\nu(0, 1)$, where $3<\nu<7$, as a prior for linear regression coefficients. Student-t distribution has heavier tails than a normal distribution, but less heavy tails than a cauchy distribution, making it able to predict further away values while still keeping most of the mass near the mean.

$$
t_{\nu_{pdf}} = \frac{\Gamma\frac{\nu+1}{2}}{\sqrt{\nu\pi}\Gamma\frac{\nu}{2}}\bigg(1+\frac{x^2}{\nu}\bigg)^{-\frac{\nu+1}{2}}
$$

[3] https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations#prior-for-linear-regression

## 3.2 Stan models

We have built the models using stan radon case study [4] as a starting point to build our regression models. We have expanded on the varying intercept model of the example by adding multiple linear and polynomial terms into the model. In our model intercept parameters vary by the zipcode while the slope parameters are shared across zipcodes.

[4] https://mc-stan.org/users/documentation/case-studies/radon.html


### Grouped multiple linear

$$
y_i=\alpha_{j[i]}+\beta x_i+\epsilon_i
$$
where $j=1,\dots,70$ denotes the group of the observation. and $\epsilon_i \sim N(0, \sigma)$. The model can also be written as $y_i \sim N(\alpha_{j[i]}+\beta x_i, \sigma)$.

```{r}
cat(readLines('models/grouped_multiple_linear.stan'), sep='\n')
```

### Grouped multiple polynomial

$$
y_i=\alpha_{j[i]}+\beta x_i+\gamma x_i^2+\epsilon_i
$$

```{r}
cat(readLines('models/grouped_multiple_polynomial.stan'), sep='\n')
```



## 3.3 Running the models

We train the models on 80%/20%-test split using 10000 first datapoints. Using all datapoints is possible, but R-will run out of memory while plotting.

```{r}
usable_numeric_columns = c("sqft_living", "grade","view", "lat", "yr_built", 
                           "sqft_living15","long", "bathrooms")
```


```{r}
training_indices = 0:8000
testing_indices = 8001:10000

used_columns = usable_numeric_columns
target_column = c("log_price")
group_column =  c("mutated_zipcode")
original_target = houseprice[,target_column]
training_data = houseprice_scaled[training_indices,used_columns]
testing_data =  houseprice_scaled[testing_indices, used_columns]
training_target = houseprice_scaled[training_indices,target_column]
testing_target_scaled =  houseprice_scaled[testing_indices, target_column]
testing_target =  houseprice[testing_indices, target_column]

X_var = training_data
X_var_pred = testing_data
y_var = training_target
group_var = houseprice[training_indices,group_column]
group_var_pred = houseprice[testing_indices,group_column]
  
data_list = list(
  X = X_var,
  X_pred = X_var_pred,
  K = ncol(X_var),
  N = nrow(X_var),
  N_pred = nrow(X_var_pred),
  N_groups = length(unique_zips),
  y = y_var,
  groups = group_var,
  groups_pred  = group_var_pred
)
head(X_var)
```



### Grouped multiple linear


```{r}
multiple_linear_fit <- stan(file = 'models/grouped_multiple_linear.stan', data = data_list)
```


```{r}
denormalize_results <- function(new_values, sd, mean){
  return (new_values * sd + mean)
}
orig_sd = sd(original_target)
orig_mean = mean(original_target)
```

```{r}
predicted_draws = extract(multiple_linear_fit)$y_pred
predicted_raws = colQuantiles(predicted_draws, probs = c(0.05, 0.5, 0.95))
predicted_prices = denormalize_results(predicted_raws, orig_sd, orig_mean)
```


```{r}
result_testing = data.frame(price = testing_target, predicted = predicted_prices)
ggpairs(result_testing, columns = c("price", "predicted.50."))
```


```{r}
mae_lin = mae(exp(testing_target),exp(predicted_prices))
mae_lin
```


 
```{r}
violin_predicted = extract(multiple_linear_fit)$y_pred
violin_predicted = exp(denormalize_results(violin_predicted, orig_sd, orig_mean))
#violin_predicted = exp(predicted_prices)
violin_groups = outer(1:nrow(violin_predicted), 1:ncol(violin_predicted),
                      FUN=function(r,c) unique_zips[group_var_pred[c]] )
violin_predicted = c(t(violin_predicted))
violin_groups = as.factor(c(t(violin_groups)))
violin_data_list_thing = data.frame(price=violin_predicted, group=violin_groups)

p <- ggplot(violin_data_list_thing, aes(x=group, y=price)) + 
  geom_violin()
p
```

### Grouped multiple polynomial

```{r}
X_var_second = X_var^2
X_var_pred_second = X_var_pred^2

#not used (third degree polynomial model data)
X_var_third = X_var^3
X_var_pred_third = X_var_pred^3

data_list = list(
  X = X_var,
  X_second = X_var_second,
  X_third = X_var_third,
  X_pred = X_var_pred,
  X_pred_second = X_var_pred_second,
  X_pred_third = X_var_pred_third,
  K = ncol(X_var),
  N = nrow(X_var),
  N_pred = nrow(X_var_pred),
  N_groups = length(unique_zips),
  y = y_var,
  groups = group_var,
  groups_pred  = group_var_pred
)
```



```{r}
multiple_polynomial_fit <- stan(file = 'models/grouped_multiple_polynomial.stan',
                                data = data_list)
```

```{r}
predicted_draws = extract(multiple_polynomial_fit)$y_pred
predicted_raws = colQuantiles(predicted_draws, probs = c(0.05, 0.5, 0.95))
predicted_prices = denormalize_results(predicted_raws, orig_sd, orig_mean)
```


```{r}
result_testing = data.frame(price = testing_target, predicted = predicted_prices)
ggpairs(result_testing, columns = c("price", "predicted.50."))
```


```{r}
mae_pol = mae(exp(testing_target),exp(predicted_prices))
mae_pol
```


# 4. Convergence diagnostics

From the plots of the models we can see that all model parameters have converged.

## Grouped multiple linear

```{r}
print(multiple_linear_fit, pars = c("alpha", "beta"))
```

```{R}
posterior_divergences <- as.array(multiple_linear_fit)
mcmc_trace(multiple_linear_fit, regex_pars = "beta")
```

```{r}
#past tree depth
get_num_max_treedepth(multiple_linear_fit)
```

## Grouped multiple polynomial


```{r}
print(multiple_polynomial_fit,  pars = c("alpha", "beta", "beta_second"))
```


```{R}
mcmc_trace(multiple_polynomial_fit, regex_pars = "beta")
```

```{R}
#past tree depth
get_num_max_treedepth(multiple_polynomial_fit)
```

# 5. Posterior predictive checking

We can see that replicated data is indistinguishable from the target

```{r}
replicated_data_lin = denormalize_results(extract(multiple_linear_fit)$y_rep, orig_sd, orig_mean)
replicated_data_pol = denormalize_results(extract(multiple_polynomial_fit)$y_rep, orig_sd, orig_mean)

plot(density(replicated_data_lin), col="red", main="Replicated posterior" )
lines(density(replicated_data_pol), col="blue")
lines(density(original_target), col="black")
legend(x="topright",
       legend=c("Linear replicated", "Polynomial Replicated", "Original data"),
       col=c("red", "blue", "black"), lty=1:1, cex=0.8)
```


```{r}
original_training_order = order(original_target[training_indices])
loo_lin <- loo(multiple_linear_fit, save_psis = TRUE)
psis_lin <- loo_lin$psis_object
lw_lin <- weights(psis_lin)
pp_check(c(original_target[training_indices]), yrep = replicated_data_lin, fun = "stat")
ppc_loo_pit_overlay(c(original_target[training_indices]), yrep = replicated_data_lin,
                    lw = lw_lin)
ppc_loo_ribbon(c(original_target[training_indices][original_training_order]),
               yrep = replicated_data_lin[,original_training_order],
               lw = lw_lin, psis_object = psis_lin)
ppc_loo_intervals(c(original_target[training_indices]),
                  yrep = replicated_data_lin, psis_object = psis_lin)
```

```{r}

loo_pol <- loo(multiple_polynomial_fit, save_psis = TRUE)
psis_pol <- loo_pol$psis_object
lw_pol <- weights(psis_pol)
pp_check(c(original_target[training_indices]), yrep = replicated_data_pol, fun = "stat")
ppc_loo_pit_overlay(c(original_target[training_indices]), yrep = replicated_data_pol,
                    lw = lw_pol)
ppc_loo_ribbon(c(original_target[training_indices][original_training_order]),
               yrep = replicated_data_pol[,original_training_order],
               lw = lw_pol, psis_object = psis_pol)
ppc_loo_intervals(c(original_target[training_indices]),
                  yrep = replicated_data_pol, psis_object = psis_pol)
```


# 6. Predictive performance assesment

From the mean squared errors we can see that the polynomial model performed better on the test set 
```{r}
# compare errors
data.frame(linear = mae_lin, polynomial = mae_pol)
```


## PSIS-lOO 

Obtained elpd information criteria values of the two models are largely the same with the polynomial model having an larger value, suggesting it is better of the two models. The k-values of the models are small suggesting the models fit the data well. 

### Multiple linear regression

```{r}
# Extract log-likelihood
multiple_linear_log_lik <- extract_log_lik(multiple_linear_fit, merge_chains = FALSE)

# PSIS-LOO elpd values
r_eff <- relative_eff(exp(multiple_linear_log_lik))
multiple_linear_loo_lin <- loo(multiple_linear_log_lik, r_eff = r_eff)

#elpd loo
multiple_linear_loo_lin
```


```{r}
pareto_k_table(multiple_linear_loo_lin)
```

```{r}
plot(multiple_linear_loo_lin, diagnostic = c("k", "n_eff"), label_points = FALSE,
  main = "PSIS diagnostic plot for ther multiple linear model")

```


### Multiple polynomial regression

```{r}
# Extract log-likelihood
multiple_polynomial_log_lik <- extract_log_lik(multiple_polynomial_fit, merge_chains = FALSE)

# PSIS-LOO elpd values
r_eff <- relative_eff(exp(multiple_polynomial_log_lik))
multiple_polynomial_loo_lin <- loo(multiple_polynomial_log_lik, r_eff = r_eff)

#elpd loo
multiple_polynomial_loo_lin
```

```{r}
pareto_k_table(multiple_polynomial_loo_lin)
```

```{r}
plot(multiple_polynomial_loo_lin, diagnostic = c("k", "n_eff"), label_points = FALSE,
  main = "PSIS diagnostic plot for ther multiple polynomial model")
```

## p_eff values

```{R}
loo_compare(x = list(multiple_linear_loo_lin, multiple_polynomial_loo_lin))
```

# 7. Discussion

In this report we have explored linear and polynomial regression models for predicting house prices. The differences between the results from the models are small, but the polynomial model performs a bit better. The mean absolute error for both models is over hundred thousand, but considering the mean of the prices is around five hundred thousand, some error is to be expected. Overall the results follow the true data.

In the future we could consider varying slope parameter by zipcode, but this has few obvious drawbacks.
There are 70 groups, so using a different beta value for each parameter for each group would increase the number of parameters of the model by 2-17 times, likely slowing the model. In addition, the number of data usable for each beta value would shrink. The dataset is large, so using most of the dataset for training, it shouldn't be a problem but with less data it could lead to overfitting. Practically it would mean that there is no relation between the effects of the parameters between different groups, e.g. the size of the building could increase price somewhere and decrease it elsewhere, which sounds counterintuitive, but could still be an avenue for future research.



